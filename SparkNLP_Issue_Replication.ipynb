{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SparkNLP_Issue_Replication.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "d0LBBUVHpLba",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!export JAVA_HOME=$(/usr/libexec/java_home -v 1.8)\n",
        "import os\n",
        "\n",
        "# Install java\n",
        "! apt-get install -y openjdk-8-jdk-headless -qq > /dev/null\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"PATH\"] = os.environ[\"JAVA_HOME\"] + \"/bin:\" + os.environ[\"PATH\"]\n",
        "! java -version\n",
        "\n",
        "# Install pyspark\n",
        "! pip install --ignore-installed pyspark==2.4.3\n",
        "\n",
        "# Install Spark NLP\n",
        "! pip install --ignore-installed spark-nlp==2.4.1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gOeRnXajpYnU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "import sparknlp \n",
        "\n",
        "spark = sparknlp.start()\n",
        "\n",
        "print(\"Spark NLP version: \", sparknlp.version())\n",
        "print(\"Apache Spark version: \", spark.version)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JJWQNBAipbcF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pyspark import SparkContext, SQLContext\n",
        "from sparknlp.pretrained import NerDLModel\n",
        "from sparknlp.pretrained import PretrainedPipeline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "at9RzjsupcP6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path = \"File Available @ https://github.com/saicharannivarthi/spark_nlp_issue_resources/blob/master/input_data.json\"\n",
        "\n",
        "oldArticlesData = spark.read.json(path)\n",
        "\n",
        "#concatenating title & content\n",
        "import pyspark\n",
        "from pyspark.sql import functions as sf\n",
        "\n",
        "inputData = oldArticlesData.withColumn('text', sf.concat(sf.col('title'),sf.lit(' . '), sf.col('content')))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0X40yhsAqrRX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sparknlp.base import *\n",
        "from sparknlp.annotator import *\n",
        "from pyspark.ml import Pipeline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_C2MNzKKpsaH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "documentAssembler = DocumentAssembler() \\\n",
        "    .setInputCol(\"text\") \\\n",
        "    .setOutputCol(\"document\")\n",
        "\n",
        "sentenceDetector = SentenceDetector() \\\n",
        "    .setInputCols([\"document\"]) \\\n",
        "    .setOutputCol(\"sentence\")\n",
        "\n",
        "regexTokenizer = Tokenizer() \\\n",
        "    .setInputCols([\"sentence\"]) \\\n",
        "    .setOutputCol(\"token\")\n",
        "\n",
        "normalizer = Normalizer()\\\n",
        "      .setInputCols([\"token\"])\\\n",
        "      .setOutputCol(\"normal\")\n",
        "      \n",
        "embeddings_bert = BertEmbeddings.pretrained(\"bert_base_cased\", lang=\"en\") \\\n",
        "    .setInputCols([\"document\", \"token\"]) \\\n",
        "    .setOutputCol('embeddings')\n",
        "\n",
        "ner_bert = NerDLModel().pretrained('ner_dl_bert') \\\n",
        "    .setInputCols([\"document\", \"token\", \"embeddings\"]) \\\n",
        "    .setOutputCol(\"ner_dl_bert\")\n",
        "     \n",
        "\n",
        "\n",
        "nerConverter_bert = NerConverter()\\\n",
        "     .setInputCols(\"document\", \"normal\", \"ner_dl_bert\")\\\n",
        "     .setOutputCol(\"ner_converter_bert\")\n",
        "\n",
        "finisher = Finisher() \\\n",
        "    .setInputCols([\"token\"]) \\\n",
        "    .setCleanAnnotations(False)\n",
        "\n",
        "# document, token, normalizer, wordEmbeddings, ner, nerConverter, finisher\n",
        "custom_pipeline_bert = Pipeline() \\\n",
        "    .setStages([\n",
        "        documentAssembler,\n",
        "        sentenceDetector,\n",
        "        regexTokenizer,\n",
        "        embeddings_bert,\n",
        "        ner_bert,\n",
        "        normalizer,\n",
        "        nerConverter_bert,\n",
        "        finisher\n",
        "    ])\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXdIFei9p2HT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "result = custom_pipeline_bert.fit(inputData).transform(inputData)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0RJ4J06pqKgu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bert_custom_ner = result.select('ner_converter_bert.metadata','ner_converter_bert.result')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cU02c9VIqMB8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bert_custom_ner.coalesce(1).write.format('json').save('Output available @ https://github.com/saicharannivarthi/spark_nlp_issue_resources/blob/master/pyspark_output.json')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}